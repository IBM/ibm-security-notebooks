{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "Goal here is to look at features and see which are most important. \n",
    "\n",
    "Steps:\n",
    "- fit a model for outlier detection, like Isolation Forest or Local Outlier Factor\n",
    "- predict the training data to label as inlier or outlier.  This is based more on just normal/network features to look for change in behavior but no necessarily bad behavior\n",
    "- fit another classifier like XGBoost/RandomForest with the outlier/inlier results as labels.  Could potentially use other features to label 'outlier' like:\n",
    "    - in QRadar offense or UBA offense\n",
    "    - virus detected (AV event)\n",
    "    - bad file hash seen on endpoint (virus/malware)\n",
    "    - threat intel bad IP accessed (XForce, reference set)\n",
    "    - bad URL category - blocked, malicious, malware\n",
    "    - high number of UBA rules or QRadar rules triggered\n",
    "    - high risk in interval\n",
    "    - high overall risk\n",
    "    - not sure how many of these could be useful to label vs just use them as a feature.  Some of these will bias the model to flag things like people who have similar behavior to people who trigger a lot of UBA rules but did not actually trigger them for example.  It might not be worth doing, and just use these as features.\n",
    "- now the classifier model could be used to predict inlier or outlier\n",
    "- plot SHAP graphs to show importance of features for each model\n",
    "\n",
    "Reference: https://github.com/slundberg/shap\n",
    "\n",
    "## Features\n",
    "The features are broken into a few buckets.  I would propose a model for related features like:\n",
    "- General are general QRadar features like number of qid, events, log sources, devices, context\n",
    "- Time is time based features like min/max/avg, events exactly on the start of hour and start of each minute\n",
    "- Network is things related to the network addresses like IP, local/remote, mac addresses\n",
    "- Port is the traffic in ranges 0 - 1024 - 49151 - max, plus unique ports in each range\n",
    "- Rules is info around QRadar and UBA BB, like unique rules, UBA risk\n",
    "- 'All Columns' is all 70+ features at once\n",
    "\n",
    "Ideas for other models:\n",
    "- Proxy: things like unique URLs, http/https traffic, URL categories, source and dest IPs\n",
    "- Windows: object name, types, domain, eventID, process nametc etc.\n",
    "- UNIX model\n",
    "- Cloud: AWS, azure, office 365.  Things like how many EC2 instances, how many files, cloud object storage, how many S3 buckets accessed\n",
    "- Authentication model - normal auth times, amount of auth, auth device (VPN/domain controller etc), auth source IP's\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following is required for running on Mac\n",
    "# %env CC=/usr/local/opt/llvm/bin/clang\n",
    "# %env CXX=/usr/local/opt/llvm/bin/clang++\n",
    "# %env LDFLAGS=\"-L/usr/local/opt/llvm/lib\"\n",
    "# %env CPPFLAGS=\"-I/usr/local/opt/llvm/include\"\n",
    "# !brew install llvm\n",
    "# !brew install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default settings, constants\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "FIGSIZE=(15,10)\n",
    "matplotlib.rcParams['figure.figsize'] = FIGSIZE\n",
    "\n",
    "# Prefixes for feature groups\n",
    "PREFIX = [\n",
    "    'General',\n",
    "    'Time',\n",
    "    'Network',\n",
    "    'Port',\n",
    "    'Rules',\n",
    "    'All Columns',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qradar import QRadar, AQL\n",
    "\n",
    "qi = QRadar(console='9.191.82.171', username='admin', token='YOUR-SERVICE-TOKEN-HERE')\n",
    "df = pd.DataFrame.from_records(qi.search(AQL.proxy_model))\n",
    "\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap, time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def test_shap(prefix):\n",
    "    print('\"%s\" feature group' % prefix)\n",
    "    \n",
    "    if prefix == 'All Columns':\n",
    "        data = df\n",
    "    else:\n",
    "        cols = ['user', 'timeslice']\n",
    "        cols.extend([col for col in df if col.startswith(prefix.lower()+'_')])\n",
    "        data = df[cols]\n",
    "        \n",
    "    features=data.drop('user',axis=1).drop('timeslice',axis=1)\n",
    "    print('%s features' % len(list(features)))\n",
    "\n",
    "    # Fit isolation forest to label outliers\n",
    "    start = time.time()\n",
    "    clf = IsolationForest(behaviour='new', contamination='auto', n_jobs=-1)\n",
    "    #clf = LocalOutlierFactor(n_jobs=-1, contamination='auto')\n",
    "    #clf = OneClassSVM()\n",
    "    try:\n",
    "        clf.fit(features)\n",
    "    except:\n",
    "        return  # skip the rest\n",
    "    predictions = clf.predict(features)\n",
    "    #predictions = clf.fit_predict(features)\n",
    "    print('took %.2f seconds to fit %s for outliers' % (time.time() - start, clf.__class__.__name__))\n",
    "    \n",
    "    #X, X_test, Y, Y_test = train_test_split(features, predictions, test_size=0.9)\n",
    "    # here we could use the other ideas/features to also change labels to be outliers\n",
    "    X = features\n",
    "    Y = predictions\n",
    "\n",
    "    # use outlier prediction from ISOF as labels for other classifier   \n",
    "    start = time.time()\n",
    "    model = XGBClassifier(n_jobs=-1)\n",
    "    #model = DecisionTreeClassifier()\n",
    "    #model = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "    model.fit(X, Y)\n",
    "    print('took %.2f seconds to fit %s using outlier labels' % (time.time() - start, model.__class__.__name__))\n",
    "\n",
    "    # fix decode error, from: https://github.com/slundberg/shap/issues/1215\n",
    "    mybooster = model.get_booster()\n",
    "    model_barr = mybooster.save_raw()[4:]\n",
    "    mybooster.save_raw = lambda: model_barr\n",
    "\n",
    "    start = time.time()\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    print('took %.2f seconds to calculate SHAP explainer and values' % (time.time() - start))\n",
    "    shap.initjs()\n",
    "    \n",
    "    # Visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "    # shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])\n",
    "    \n",
    "    # All the predictions plotty vertically (same as above)\n",
    "    # shap.force_plot(explainer.expected_value, shap_values, X)\n",
    "    \n",
    "    # For one specific feature \"RM\"\n",
    "    # shap.dependence_plot(\"RM\", shap_values, X)\n",
    "    \n",
    "    shap.summary_plot(shap_values, X)\n",
    "    try:\n",
    "        shap.summary_plot(shap_values, X, plot_type=\"violin\")\n",
    "    except:\n",
    "        pass\n",
    "    shap.summary_plot(shap_values, X, plot_type=\"bar\")\n",
    "    \n",
    "    print('')\n",
    "    \n",
    "for prefix in PREFIX:\n",
    "    test_shap(prefix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
